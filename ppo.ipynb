{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import time\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style()\n",
    "\n",
    "import gym\n",
    "gym.logger.set_level(40)\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Use CUDA</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device   = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Create Environments</h2>\n",
    "16スレッドで環境を作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-12:\n",
      "Process Process-8:\n",
      "Process Process-6:\n",
      "Process Process-5:\n",
      "Process Process-9:\n",
      "Process Process-10:\n",
      "Process Process-3:\n",
      "Process Process-7:\n",
      "Process Process-4:\n",
      "Process Process-13:\n",
      "Process Process-16:\n",
      "Process Process-1:\n",
      "Process Process-14:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/near/git/TorchGAIL/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Process Process-15:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/near/git/TorchGAIL/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/near/git/TorchGAIL/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/near/git/TorchGAIL/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/near/git/TorchGAIL/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/near/git/TorchGAIL/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Process Process-11:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/near/git/TorchGAIL/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/near/git/TorchGAIL/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/near/git/TorchGAIL/common/multiprocessing_env.py\", line 16, in worker\n",
      "    remote.send((ob, reward, done, info))\n",
      "  File \"/home/near/git/TorchGAIL/common/multiprocessing_env.py\", line 16, in worker\n",
      "    remote.send((ob, reward, done, info))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/near/git/TorchGAIL/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 206, in send\n",
      "    self._send_bytes(_ForkingPickler.dumps(obj))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 206, in send\n",
      "    self._send_bytes(_ForkingPickler.dumps(obj))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/near/git/TorchGAIL/common/multiprocessing_env.py\", line 13, in worker\n",
      "    ob, reward, done, info = env.step(data)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/near/git/TorchGAIL/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "Process Process-2:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/home/near/git/TorchGAIL/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/wrappers/time_limit.py\", line 31, in step\n",
      "    observation, reward, done, info = self.env.step(action)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/mujoco/pusher.py\", line 21, in step\n",
      "    self.do_simulation(a, self.frame_skip)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/near/git/TorchGAIL/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/mujoco/mujoco_env.py\", line 100, in do_simulation\n",
      "    self.sim.step()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/near/git/TorchGAIL/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n"
     ]
    }
   ],
   "source": [
    "from common.multiprocessing_env import SubprocVecEnv\n",
    "\n",
    "num_envs = 16\n",
    "env_name = \"Pusher-v2\"\n",
    "\n",
    "def make_env():\n",
    "    def _thunk():\n",
    "        env = gym.make(env_name)\n",
    "        return env\n",
    "\n",
    "    return _thunk\n",
    "\n",
    "envs = [make_env() for i in range(num_envs)]\n",
    "envs = SubprocVecEnv(envs)\n",
    "\n",
    "env = gym.make(env_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Neural Network</h2>\n",
    "* nn.Relu→nn.Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.normal_(m.weight, mean=0., std=0.1)\n",
    "        nn.init.constant_(m.bias, 0.1)\n",
    "        \n",
    "\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs, hidden_size, std=0.0):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        \n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Linear(num_inputs, hidden_size),\n",
    "#            nn.ReLU(),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "        \n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Linear(num_inputs, hidden_size),\n",
    "#            nn.ReLU(),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, num_outputs),\n",
    "        )\n",
    "        self.log_std = nn.Parameter(torch.ones(1, num_outputs) * std)\n",
    "        \n",
    "        self.apply(init_weights)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        value = self.critic(x)\n",
    "        mu    = self.actor(x)\n",
    "        std   = self.log_std.exp().expand_as(mu)\n",
    "        dist  = Normal(mu, std)\n",
    "        return dist, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot(frame_idx, rewards):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('frame %s. reward: %s' % (frame_idx, rewards[-1]))\n",
    "    plt.plot(rewards)\n",
    "    plt.show()\n",
    "    \n",
    "def test_env(vis=False):\n",
    "    state = env.reset()\n",
    "    if vis: env.render()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        state = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "        dist, _ = model(state)\n",
    "        next_state, reward, done, _ = env.step(dist.sample().cpu().numpy()[0])\n",
    "        state = next_state\n",
    "        if vis: \n",
    "            env.render()\n",
    "            time.sleep(0.05)\n",
    "        total_reward += reward\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>GAE</h2>\n",
    "* gamma 0.99→0.995 tau 0.95→0.97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_gae(next_value, rewards, masks, values, gamma=0.995, tau=0.97):\n",
    "    values = values + [next_value]\n",
    "    gae = 0\n",
    "    returns = []\n",
    "    for step in reversed(range(len(rewards))):\n",
    "        delta = rewards[step] + gamma * values[step + 1] * masks[step] - values[step]\n",
    "        gae = delta + gamma * tau * masks[step] * gae\n",
    "        returns.insert(0, gae + values[step])\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Proximal Policy Optimization Algorithm</h1>\n",
    "<h2><a href=\"https://arxiv.org/abs/1707.06347\">Arxiv</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ppo_iter(mini_batch_size, states, actions, log_probs, returns, advantage):\n",
    "    batch_size = states.size(0)\n",
    "    for _ in range(batch_size // mini_batch_size):\n",
    "        rand_ids = np.random.randint(0, batch_size, mini_batch_size)\n",
    "        yield states[rand_ids, :], actions[rand_ids, :], log_probs[rand_ids, :], returns[rand_ids, :], advantage[rand_ids, :]\n",
    "        \n",
    "        \n",
    "\n",
    "def ppo_update(ppo_epochs, mini_batch_size, states, actions, log_probs, returns, advantages, clip_param=0.2):\n",
    "    for _ in range(ppo_epochs):\n",
    "        for state, action, old_log_probs, return_, advantage in ppo_iter(mini_batch_size, states, actions, log_probs, returns, advantages):\n",
    "            dist, value = model(state)\n",
    "            entropy = dist.entropy().mean()\n",
    "            new_log_probs = dist.log_prob(action)\n",
    "\n",
    "            ratio = (new_log_probs - old_log_probs).exp()\n",
    "            surr1 = ratio * advantage\n",
    "            surr2 = torch.clamp(ratio, 1.0 - clip_param, 1.0 + clip_param) * advantage\n",
    "\n",
    "            actor_loss  = - torch.min(surr1, surr2).mean()\n",
    "            critic_loss = (return_ - value).pow(2).mean()\n",
    "\n",
    "            loss = 0.5 * critic_loss + actor_loss - 0.001 * entropy\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* hidden_size 256->64\n",
    "* num_steps 20->500\n",
    "* mini_batch_size 5→64\n",
    "* ppo epochs 4→10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_inputs  = envs.observation_space.shape[0]\n",
    "num_outputs = envs.action_space.shape[0]\n",
    "\n",
    "#Hyper params:\n",
    "hidden_size      = 256\n",
    "lr               = 3e-4\n",
    "num_steps        = 500\n",
    "mini_batch_size  = 4000\n",
    "ppo_epochs       = 10\n",
    "threshold_reward = 5000\n",
    "\n",
    "model = ActorCritic(num_inputs, num_outputs, hidden_size).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_frames = 20000000\n",
    "frame_idx  = 0\n",
    "test_rewards = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-fdc7486d0ac0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mlog_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/TorchGAIL/common/multiprocessing_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/TorchGAIL/common/multiprocessing_env.py\u001b[0m in \u001b[0;36mstep_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mremote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mremote\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremotes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaiting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrews\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/TorchGAIL/common/multiprocessing_env.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mremote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mremote\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremotes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaiting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrews\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "state = envs.reset()\n",
    "early_stop = False\n",
    "\n",
    "while frame_idx < max_frames and not early_stop:\n",
    "\n",
    "    log_probs = []\n",
    "    values    = []\n",
    "    states    = []\n",
    "    actions   = []\n",
    "    rewards   = []\n",
    "    masks     = []\n",
    "    entropy = 0\n",
    "\n",
    "    for _ in range(num_steps):\n",
    "        state = torch.FloatTensor(state).to(device)\n",
    "        dist, value = model(state)\n",
    "\n",
    "        action = dist.sample()\n",
    "        next_state, reward, done, _ = envs.step(action.cpu().numpy())\n",
    "\n",
    "        log_prob = dist.log_prob(action)\n",
    "        entropy += dist.entropy().mean()\n",
    "        \n",
    "        log_probs.append(log_prob)\n",
    "        values.append(value)\n",
    "        rewards.append(torch.FloatTensor(reward).unsqueeze(1).to(device))\n",
    "        masks.append(torch.FloatTensor(1 - done).unsqueeze(1).to(device))\n",
    "        \n",
    "        states.append(state)\n",
    "        actions.append(action)\n",
    "        \n",
    "        state = next_state\n",
    "        frame_idx += 1\n",
    "        \n",
    "        if frame_idx % 1000 == 0:\n",
    "            test_reward = np.mean([test_env() for _ in range(10)])\n",
    "            test_rewards.append(test_reward)\n",
    "            plot(frame_idx, test_rewards)\n",
    "            if test_reward > threshold_reward: early_stop = True\n",
    "            \n",
    "\n",
    "    next_state = torch.FloatTensor(next_state).to(device)\n",
    "    _, next_value = model(next_state)\n",
    "    returns = compute_gae(next_value, rewards, masks, values)\n",
    "\n",
    "    returns   = torch.cat(returns).detach()\n",
    "    log_probs = torch.cat(log_probs).detach()\n",
    "    values    = torch.cat(values).detach()\n",
    "    states    = torch.cat(states)\n",
    "    actions   = torch.cat(actions)\n",
    "    advantage = returns - values\n",
    "    \n",
    "    ppo_update(ppo_epochs, mini_batch_size, states, actions, log_probs, returns, advantage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Saving trajectories for GAIL</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import count\n",
    "\n",
    "max_expert_num = 250000\n",
    "num_steps = 0\n",
    "expert_traj = []\n",
    "\n",
    "for i_episode in count():\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    \n",
    "    while not done:\n",
    "        state = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "        dist, _ = model(state)\n",
    "        action = dist.sample().cpu().numpy()[0]\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "        expert_traj.append(np.hstack([state, action]))\n",
    "        num_steps += 1\n",
    "    \n",
    "    print(\"episode:\", i_episode, \"reward:\", total_reward)\n",
    "    \n",
    "    if num_steps >= max_expert_num:\n",
    "        break\n",
    "        \n",
    "expert_traj = np.stack(expert_traj)\n",
    "print()\n",
    "print(expert_traj.shape)\n",
    "print()\n",
    "np.save(\"expert_traj.npy\", expert_traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-57.045960943941914"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_env(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL-a",
   "language": "python",
   "name": "rl-a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
