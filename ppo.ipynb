{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import time\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style()\n",
    "\n",
    "import gym\n",
    "gym.logger.set_level(40)\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Use CUDA</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device   = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Create Environments</h2>\n",
    "16スレッドで環境を作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-7:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n    self.run()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n    self._target(*self._args, **self._kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/git/TorchGAIL/common/multiprocessing_env.py\", line 9, in worker\n    env = env_fn_wrapper.x()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-6:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"<ipython-input-4-4ec9484a328e>\", line 8, in _thunk\n    env = gym.make(env_name)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n    self.run()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/registration.py\", line 167, in make\n    return registry.make(id)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n    self._target(*self._args, **self._kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/registration.py\", line 119, in make\n    env = spec.make()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/git/TorchGAIL/common/multiprocessing_env.py\", line 9, in worker\n    env = env_fn_wrapper.x()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/registration.py\", line 85, in make\n    cls = load(self._entry_point)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/registration.py\", line 14, in load\n    result = entry_point.load(False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"<ipython-input-4-4ec9484a328e>\", line 8, in _thunk\n    env = gym.make(env_name)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/pkg_resources/__init__.py\", line 2229, in load\n    return self.resolve()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/registration.py\", line 167, in make\n    return registry.make(id)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/pkg_resources/__init__.py\", line 2235, in resolve\n    module = __import__(self.module_name, fromlist=['__name__'], level=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/registration.py\", line 119, in make\n    env = spec.make()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/registration.py\", line 85, in make\n    cls = load(self._entry_point)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/mujoco/__init__.py\", line 1, in <module>\n    from gym.envs.mujoco.mujoco_env import MujocoEnv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/registration.py\", line 14, in load\n    result = entry_point.load(False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/pkg_resources/__init__.py\", line 2229, in load\n    return self.resolve()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/mujoco/mujoco_env.py\", line 11, in <module>\n    import mujoco_py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/pkg_resources/__init__.py\", line 2235, in resolve\n    module = __import__(self.module_name, fromlist=['__name__'], level=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/mujoco_py/__init__.py\", line 1, in <module>\n    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/mujoco/__init__.py\", line 1, in <module>\n    from gym.envs.mujoco.mujoco_env import MujocoEnv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/mujoco/mujoco_env.py\", line 11, in <module>\n    import mujoco_py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/mujoco_py/builder.py\", line 469, in <module>\n    cymj = load_cython_ext(mjpro_path)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/mujoco_py/builder.py\", line 69, in load_cython_ext\n    _ensure_set_env_var(\"LD_LIBRARY_PATH\", lib_path)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/mujoco_py/__init__.py\", line 1, in <module>\n    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/mujoco_py/builder.py\", line 102, in _ensure_set_env_var\n    var_name, var_name, lib_path))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/mujoco_py/builder.py\", line 469, in <module>\n    cymj = load_cython_ext(mjpro_path)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/mujoco_py/builder.py\", line 69, in load_cython_ext\n    _ensure_set_env_var(\"LD_LIBRARY_PATH\", lib_path)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception: \nMissing path to your environment variable. \nCurrent values LD_LIBRARY_PATH=\nPlease add following line to .bashrc:\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/near/.mujoco/mjpro150/bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/mujoco_py/builder.py\", line 102, in _ensure_set_env_var\n    var_name, var_name, lib_path))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception: \nMissing path to your environment variable. \nCurrent values LD_LIBRARY_PATH=\nPlease add following line to .bashrc:\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/near/.mujoco/mjpro150/bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n    self.run()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-9:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n    self._target(*self._args, **self._kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n    self.run()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/git/TorchGAIL/common/multiprocessing_env.py\", line 9, in worker\n    env = env_fn_wrapper.x()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"<ipython-input-4-4ec9484a328e>\", line 8, in _thunk\n    env = gym.make(env_name)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n    self._target(*self._args, **self._kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n    self.run()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/git/TorchGAIL/common/multiprocessing_env.py\", line 9, in worker\n    env = env_fn_wrapper.x()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/registration.py\", line 167, in make\n    return registry.make(id)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-8:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n    self._target(*self._args, **self._kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/registration.py\", line 119, in make\n    env = spec.make()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"<ipython-input-4-4ec9484a328e>\", line 8, in _thunk\n    env = gym.make(env_name)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/registration.py\", line 167, in make\n    return registry.make(id)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/registration.py\", line 85, in make\n    cls = load(self._entry_point)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n    self.run()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/registration.py\", line 119, in make\n    env = spec.make()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/git/TorchGAIL/common/multiprocessing_env.py\", line 9, in worker\n    env = env_fn_wrapper.x()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"<ipython-input-4-4ec9484a328e>\", line 8, in _thunk\n    env = gym.make(env_name)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/registration.py\", line 14, in load\n    result = entry_point.load(False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/registration.py\", line 85, in make\n    cls = load(self._entry_point)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n    self._target(*self._args, **self._kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/registration.py\", line 167, in make\n    return registry.make(id)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/pkg_resources/__init__.py\", line 2229, in load\n    return self.resolve()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n    self.run()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/registration.py\", line 14, in load\n    result = entry_point.load(False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/git/TorchGAIL/common/multiprocessing_env.py\", line 9, in worker\n    env = env_fn_wrapper.x()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-10:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/pkg_resources/__init__.py\", line 2235, in resolve\n    module = __import__(self.module_name, fromlist=['__name__'], level=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n    self._target(*self._args, **self._kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/registration.py\", line 119, in make\n    env = spec.make()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-14:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"<ipython-input-4-4ec9484a328e>\", line 8, in _thunk\n    env = gym.make(env_name)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/git/TorchGAIL/common/multiprocessing_env.py\", line 9, in worker\n    env = env_fn_wrapper.x()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-16:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/mujoco/__init__.py\", line 1, in <module>\n    from gym.envs.mujoco.mujoco_env import MujocoEnv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/pkg_resources/__init__.py\", line 2229, in load\n    return self.resolve()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/mujoco/mujoco_env.py\", line 11, in <module>\n    import mujoco_py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/registration.py\", line 167, in make\n    return registry.make(id)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"<ipython-input-4-4ec9484a328e>\", line 8, in _thunk\n    env = gym.make(env_name)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n    self.run()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/pkg_resources/__init__.py\", line 2235, in resolve\n    module = __import__(self.module_name, fromlist=['__name__'], level=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/registration.py\", line 85, in make\n    cls = load(self._entry_point)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/mujoco/__init__.py\", line 1, in <module>\n    from gym.envs.mujoco.mujoco_env import MujocoEnv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/mujoco/mujoco_env.py\", line 11, in <module>\n    import mujoco_py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/mujoco_py/__init__.py\", line 1, in <module>\n    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n    self._target(*self._args, **self._kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/mujoco_py/builder.py\", line 469, in <module>\n    cymj = load_cython_ext(mjpro_path)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/registration.py\", line 119, in make\n    env = spec.make()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/mujoco_py/builder.py\", line 69, in load_cython_ext\n    _ensure_set_env_var(\"LD_LIBRARY_PATH\", lib_path)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/mujoco_py/__init__.py\", line 1, in <module>\n    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/mujoco_py/builder.py\", line 102, in _ensure_set_env_var\n    var_name, var_name, lib_path))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/registration.py\", line 167, in make\n    return registry.make(id)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-12:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception: \nMissing path to your environment variable. \nCurrent values LD_LIBRARY_PATH=\nPlease add following line to .bashrc:\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/near/.mujoco/mjpro150/bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/mujoco_py/builder.py\", line 469, in <module>\n    cymj = load_cython_ext(mjpro_path)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n    self.run()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/registration.py\", line 14, in load\n    result = entry_point.load(False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/registration.py\", line 85, in make\n    cls = load(self._entry_point)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/mujoco_py/builder.py\", line 69, in load_cython_ext\n    _ensure_set_env_var(\"LD_LIBRARY_PATH\", lib_path)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/registration.py\", line 119, in make\n    env = spec.make()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/mujoco_py/builder.py\", line 102, in _ensure_set_env_var\n    var_name, var_name, lib_path))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n    self.run()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n    self._target(*self._args, **self._kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception: \nMissing path to your environment variable. \nCurrent values LD_LIBRARY_PATH=\nPlease add following line to .bashrc:\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/near/.mujoco/mjpro150/bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/pkg_resources/__init__.py\", line 2229, in load\n    return self.resolve()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/git/TorchGAIL/common/multiprocessing_env.py\", line 9, in worker\n    env = env_fn_wrapper.x()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/pkg_resources/__init__.py\", line 2235, in resolve\n    module = __import__(self.module_name, fromlist=['__name__'], level=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n    self._target(*self._args, **self._kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/git/TorchGAIL/common/multiprocessing_env.py\", line 9, in worker\n    env = env_fn_wrapper.x()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/mujoco/__init__.py\", line 1, in <module>\n    from gym.envs.mujoco.mujoco_env import MujocoEnv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/git/TorchGAIL/common/multiprocessing_env.py\", line 9, in worker\n    env = env_fn_wrapper.x()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n    self.run()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/registration.py\", line 85, in make\n    cls = load(self._entry_point)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"<ipython-input-4-4ec9484a328e>\", line 8, in _thunk\n    env = gym.make(env_name)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"<ipython-input-4-4ec9484a328e>\", line 8, in _thunk\n    env = gym.make(env_name)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/registration.py\", line 167, in make\n    return registry.make(id)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n    self._target(*self._args, **self._kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/registration.py\", line 119, in make\n    env = spec.make()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/mujoco/mujoco_env.py\", line 11, in <module>\n    import mujoco_py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n    self.run()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n    self.run()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n    self._target(*self._args, **self._kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/registration.py\", line 85, in make\n    cls = load(self._entry_point)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/mujoco_py/__init__.py\", line 1, in <module>\n    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/git/TorchGAIL/common/multiprocessing_env.py\", line 9, in worker\n    env = env_fn_wrapper.x()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/git/TorchGAIL/common/multiprocessing_env.py\", line 9, in worker\n    env = env_fn_wrapper.x()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n    self._target(*self._args, **self._kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"<ipython-input-4-4ec9484a328e>\", line 8, in _thunk\n    env = gym.make(env_name)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"<ipython-input-4-4ec9484a328e>\", line 8, in _thunk\n    env = gym.make(env_name)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/registration.py\", line 14, in load\n    result = entry_point.load(False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/registration.py\", line 14, in load\n    result = entry_point.load(False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"<ipython-input-4-4ec9484a328e>\", line 8, in _thunk\n    env = gym.make(env_name)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/registration.py\", line 167, in make\n    return registry.make(id)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/mujoco_py/builder.py\", line 469, in <module>\n    cymj = load_cython_ext(mjpro_path)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/pkg_resources/__init__.py\", line 2229, in load\n    return self.resolve()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/git/TorchGAIL/common/multiprocessing_env.py\", line 9, in worker\n    env = env_fn_wrapper.x()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/pkg_resources/__init__.py\", line 2229, in load\n    return self.resolve()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/registration.py\", line 167, in make\n    return registry.make(id)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/registration.py\", line 167, in make\n    return registry.make(id)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/pkg_resources/__init__.py\", line 2235, in resolve\n    module = __import__(self.module_name, fromlist=['__name__'], level=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/registration.py\", line 167, in make\n    return registry.make(id)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/registration.py\", line 119, in make\n    env = spec.make()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/mujoco/__init__.py\", line 1, in <module>\n    from gym.envs.mujoco.mujoco_env import MujocoEnv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/registration.py\", line 85, in make\n    cls = load(self._entry_point)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/mujoco/mujoco_env.py\", line 11, in <module>\n    import mujoco_py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/registration.py\", line 14, in load\n    result = entry_point.load(False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/mujoco_py/builder.py\", line 69, in load_cython_ext\n    _ensure_set_env_var(\"LD_LIBRARY_PATH\", lib_path)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/pkg_resources/__init__.py\", line 2229, in load\n    return self.resolve()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/mujoco_py/__init__.py\", line 1, in <module>\n    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/registration.py\", line 14, in load\n    result = entry_point.load(False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/pkg_resources/__init__.py\", line 2235, in resolve\n    module = __import__(self.module_name, fromlist=['__name__'], level=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-13:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"<ipython-input-4-4ec9484a328e>\", line 8, in _thunk\n    env = gym.make(env_name)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/registration.py\", line 119, in make\n    env = spec.make()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/pkg_resources/__init__.py\", line 2235, in resolve\n    module = __import__(self.module_name, fromlist=['__name__'], level=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/mujoco_py/builder.py\", line 102, in _ensure_set_env_var\n    var_name, var_name, lib_path))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/mujoco/__init__.py\", line 1, in <module>\n    from gym.envs.mujoco.mujoco_env import MujocoEnv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/mujoco_py/builder.py\", line 469, in <module>\n    cymj = load_cython_ext(mjpro_path)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/registration.py\", line 119, in make\n    env = spec.make()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/pkg_resources/__init__.py\", line 2229, in load\n    return self.resolve()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/mujoco/mujoco_env.py\", line 11, in <module>\n    import mujoco_py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception: \nMissing path to your environment variable. \nCurrent values LD_LIBRARY_PATH=\nPlease add following line to .bashrc:\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/near/.mujoco/mjpro150/bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/registration.py\", line 119, in make\n    env = spec.make()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/registration.py\", line 85, in make\n    cls = load(self._entry_point)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/mujoco/__init__.py\", line 1, in <module>\n    from gym.envs.mujoco.mujoco_env import MujocoEnv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-11:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/pkg_resources/__init__.py\", line 2235, in resolve\n    module = __import__(self.module_name, fromlist=['__name__'], level=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/mujoco_py/__init__.py\", line 1, in <module>\n    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/registration.py\", line 85, in make\n    cls = load(self._entry_point)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/mujoco/mujoco_env.py\", line 11, in <module>\n    import mujoco_py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/registration.py\", line 14, in load\n    result = entry_point.load(False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/pkg_resources/__init__.py\", line 2229, in load\n    return self.resolve()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/registration.py\", line 14, in load\n    result = entry_point.load(False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/mujoco_py/__init__.py\", line 1, in <module>\n    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/pkg_resources/__init__.py\", line 2229, in load\n    return self.resolve()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/mujoco_py/builder.py\", line 469, in <module>\n    cymj = load_cython_ext(mjpro_path)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/mujoco/__init__.py\", line 1, in <module>\n    from gym.envs.mujoco.mujoco_env import MujocoEnv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/pkg_resources/__init__.py\", line 2235, in resolve\n    module = __import__(self.module_name, fromlist=['__name__'], level=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n    self.run()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n    self.run()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/near/RL-a/lib/python3.6/site-packages/gym/envs/mujoco/mujoco_env.py\", line 11, in <module>\n    import mujoco_py\n"
     ]
    }
   ],
   "source": [
    "from common.multiprocessing_env import SubprocVecEnv\n",
    "\n",
    "num_envs = 16\n",
    "env_name = \"Pusher-v2\"\n",
    "\n",
    "def make_env():\n",
    "    def _thunk():\n",
    "        env = gym.make(env_name)\n",
    "        return env\n",
    "\n",
    "    return _thunk\n",
    "\n",
    "envs = [make_env() for i in range(num_envs)]\n",
    "envs = SubprocVecEnv(envs)\n",
    "\n",
    "env = gym.make(env_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Neural Network</h2>\n",
    "* nn.Relu→nn.Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.normal_(m.weight, mean=0., std=0.1)\n",
    "        nn.init.constant_(m.bias, 0.1)\n",
    "        \n",
    "\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs, hidden_size, std=0.0):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        \n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Linear(num_inputs, hidden_size),\n",
    "#            nn.ReLU(),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "        \n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Linear(num_inputs, hidden_size),\n",
    "#            nn.ReLU(),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, num_outputs),\n",
    "        )\n",
    "        self.log_std = nn.Parameter(torch.ones(1, num_outputs) * std)\n",
    "        \n",
    "        self.apply(init_weights)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        value = self.critic(x)\n",
    "        mu    = self.actor(x)\n",
    "        std   = self.log_std.exp().expand_as(mu)\n",
    "        dist  = Normal(mu, std)\n",
    "        return dist, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot(frame_idx, rewards, suc_rate):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('frame %s. reward: %s' % (frame_idx, rewards[-1]))\n",
    "    plt.plot(rewards)\n",
    "    plt.subplot(132)\n",
    "    plt.title('success_rate')\n",
    "    plt.plot(suc_rate)\n",
    "    plt.show()\n",
    "def test_env(vis=False):\n",
    "    state = env.reset()\n",
    "    if vis: env.render()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        state = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "        dist, _ = model(state)\n",
    "        next_state, reward, done, _ = env.step(dist.sample().cpu().numpy()[0])\n",
    "        state = next_state\n",
    "        if vis: \n",
    "            env.render()\n",
    "            time.sleep(0.05)\n",
    "        total_reward += reward\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>GAE</h2>\n",
    "* gamma 0.99→0.995 tau 0.95→0.97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_gae(next_value, rewards, masks, values, gamma=0.99, tau=0.95):\n",
    "    values = values + [next_value]\n",
    "    gae = 0\n",
    "    returns = []\n",
    "    for step in reversed(range(len(rewards))):\n",
    "        delta = rewards[step] + gamma * values[step + 1] * masks[step] - values[step]\n",
    "        gae = delta + gamma * tau * masks[step] * gae\n",
    "        returns.insert(0, gae + values[step])\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Proximal Policy Optimization Algorithm</h1>\n",
    "<h2><a href=\"https://arxiv.org/abs/1707.06347\">Arxiv</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ppo_iter(mini_batch_size, states, actions, log_probs, returns, advantage):\n",
    "    batch_size = states.size(0)\n",
    "    for _ in range(batch_size // mini_batch_size):\n",
    "        rand_ids = np.random.randint(0, batch_size, mini_batch_size)\n",
    "        yield states[rand_ids, :], actions[rand_ids, :], log_probs[rand_ids, :], returns[rand_ids, :], advantage[rand_ids, :]\n",
    "        \n",
    "        \n",
    "\n",
    "def ppo_update(ppo_epochs, mini_batch_size, states, actions, log_probs, returns, advantages, clip_param=0.2):\n",
    "    for _ in range(ppo_epochs):\n",
    "        for state, action, old_log_probs, return_, advantage in ppo_iter(mini_batch_size, states, actions, log_probs, returns, advantages):\n",
    "            dist, value = model(state)\n",
    "            entropy = dist.entropy().mean()\n",
    "            new_log_probs = dist.log_prob(action)\n",
    "\n",
    "            ratio = (new_log_probs - old_log_probs).exp()\n",
    "            surr1 = ratio * advantage\n",
    "            surr2 = torch.clamp(ratio, 1.0 - clip_param, 1.0 + clip_param) * advantage\n",
    "\n",
    "            actor_loss  = - torch.min(surr1, surr2).mean()\n",
    "            critic_loss = (return_ - value).pow(2).mean()\n",
    "\n",
    "            loss = 0.5 * critic_loss + actor_loss - 0.001 * entropy\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_inputs  = envs.observation_space.shape[0]\n",
    "num_outputs = envs.action_space.shape[0]\n",
    "\n",
    "#Hyper params:\n",
    "hidden_size      = 128\n",
    "lr               = 3e-4\n",
    "num_steps        = 100\n",
    "mini_batch_size  = 32\n",
    "ppo_epochs       = 10\n",
    "threshold_reward = 5000\n",
    "\n",
    "model = ActorCritic(num_inputs, num_outputs, hidden_size).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_frames = 20000000\n",
    "plot_interval = 1000\n",
    "frame_idx  = 0\n",
    "test_rewards = []\n",
    "success_num = 0\n",
    "success_rates = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-5c4502d21ee4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0madvantage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mppo_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mppo_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madvantage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-7e55721e6f86>\u001b[0m in \u001b[0;36mppo_update\u001b[0;34m(ppo_epochs, mini_batch_size, states, actions, log_probs, returns, advantages, clip_param)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/RL-a/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/RL-a/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "state = envs.reset()\n",
    "early_stop = False\n",
    "\n",
    "while frame_idx < max_frames and not early_stop:\n",
    "\n",
    "    log_probs = []\n",
    "    values    = []\n",
    "    states    = []\n",
    "    actions   = []\n",
    "    rewards   = []\n",
    "    masks     = []\n",
    "    entropy = 0\n",
    "\n",
    "    for _ in range(num_steps):\n",
    "        state = torch.FloatTensor(state).to(device)\n",
    "        dist, value = model(state)\n",
    "\n",
    "        action = dist.sample()\n",
    "        next_state, reward, done, info = envs.step(action.cpu().numpy())\n",
    "        achieve_reward = np.empty((num_envs, 1))\n",
    "        for i,x in enumerate(info):achieve_reward[i] = [x[\"achieve\"]]\n",
    " \n",
    "        log_prob = dist.log_prob(action)\n",
    "        entropy += dist.entropy().mean()\n",
    "        \n",
    "        log_probs.append(log_prob)\n",
    "        values.append(value)\n",
    "        rewards.append(torch.FloatTensor(reward).unsqueeze(1).to(device))\n",
    "        masks.append(torch.FloatTensor(1 - done).unsqueeze(1).to(device))\n",
    "        \n",
    "        states.append(state)\n",
    "        actions.append(action)\n",
    "        \n",
    "        state = next_state\n",
    "        frame_idx += 1\n",
    "        \n",
    "#        if frame_idx % num_steps == 0:\n",
    "#            success_num += np.sum(achieve_reward)\n",
    "    success_num += np.sum(achieve_reward)\n",
    "    if frame_idx % plot_interval== 0:\n",
    "        test_reward = np.mean([test_env() for _ in range(10)])\n",
    "        test_rewards.append(test_reward)\n",
    "        success_rates.append(success_num/(num_envs*(plot_interval/num_steps)))\n",
    "        plot(frame_idx, test_rewards, success_rates)\n",
    "        success_num = 0\n",
    "        if test_reward > threshold_reward: early_stop = True\n",
    "    next_state = torch.FloatTensor(next_state).to(device)\n",
    "    _, next_value = model(next_state)\n",
    "    returns = compute_gae(next_value, rewards, masks, values)\n",
    "\n",
    "    returns   = torch.cat(returns).detach()\n",
    "    log_probs = torch.cat(log_probs).detach()\n",
    "    values    = torch.cat(values).detach()\n",
    "    states    = torch.cat(states)\n",
    "    actions   = torch.cat(actions)\n",
    "    advantage = returns - values\n",
    "    \n",
    "    ppo_update(ppo_epochs, mini_batch_size, states, actions, log_probs, returns, advantage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Saving trajectories for GAIL</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_env(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0 reward: -152.75984214833295\n",
      "episode: 1 reward: -163.98071384420572\n",
      "episode: 2 reward: -147.91589183822563\n",
      "episode: 3 reward: -141.85844085804908\n",
      "episode: 4 reward: -149.87199080753666\n",
      "episode: 5 reward: -139.8320496147164\n",
      "episode: 6 reward: -130.01598398071363\n",
      "episode: 7 reward: -148.80867871313436\n",
      "episode: 8 reward: -143.27881265149347\n",
      "episode: 9 reward: -157.54674783724874\n",
      "episode: 10 reward: -151.45881326475882\n",
      "episode: 11 reward: -145.94865671327477\n",
      "episode: 12 reward: -151.91703867348633\n",
      "episode: 13 reward: -142.7956025590396\n",
      "episode: 14 reward: -139.80931419596502\n",
      "episode: 15 reward: -151.96650980686792\n",
      "episode: 16 reward: -144.52002041973765\n",
      "episode: 17 reward: -139.50468082543065\n",
      "episode: 18 reward: -167.1400071845581\n",
      "episode: 19 reward: -145.8557244826802\n",
      "episode: 20 reward: -143.73619016951312\n",
      "episode: 21 reward: -142.02390906184857\n",
      "episode: 22 reward: -161.59747289267938\n",
      "episode: 23 reward: -141.7635723548118\n",
      "episode: 24 reward: -140.72594332587764\n",
      "episode: 25 reward: -158.5465507376223\n",
      "episode: 26 reward: -165.68332750839423\n",
      "episode: 27 reward: -136.76020547816483\n",
      "episode: 28 reward: -154.29635161857925\n",
      "episode: 29 reward: -143.30243439069594\n",
      "episode: 30 reward: -146.1378984950344\n",
      "episode: 31 reward: -138.33598126077166\n",
      "episode: 32 reward: -148.39106879578452\n",
      "episode: 33 reward: -164.65990736002885\n",
      "episode: 34 reward: -149.05940699933225\n",
      "episode: 35 reward: -135.20296167979848\n",
      "episode: 36 reward: -152.64360905624272\n",
      "episode: 37 reward: -163.42698531294553\n",
      "episode: 38 reward: -140.57581929999725\n",
      "episode: 39 reward: -142.60405831254022\n",
      "episode: 40 reward: -143.13315193105458\n",
      "episode: 41 reward: -157.72796949802742\n",
      "episode: 42 reward: -149.5489894476517\n",
      "episode: 43 reward: -142.0212861134076\n",
      "episode: 44 reward: -154.7274003081272\n",
      "episode: 45 reward: -151.05259535527267\n",
      "episode: 46 reward: -138.2096511698106\n",
      "episode: 47 reward: -155.40560833978785\n",
      "episode: 48 reward: -153.3426677986814\n",
      "episode: 49 reward: -154.90744260221402\n",
      "episode: 50 reward: -144.93034095777742\n",
      "episode: 51 reward: -135.69463461592906\n",
      "episode: 52 reward: -137.10389120621986\n",
      "episode: 53 reward: -121.70927690260686\n",
      "episode: 54 reward: -147.19901302998457\n",
      "episode: 55 reward: -148.62094243820454\n",
      "episode: 56 reward: -141.82696401859286\n",
      "episode: 57 reward: -132.99766562530067\n",
      "episode: 58 reward: -143.56824557043737\n",
      "episode: 59 reward: -158.05729363516974\n",
      "episode: 60 reward: -150.367726155728\n",
      "episode: 61 reward: -144.17037854648188\n",
      "episode: 62 reward: -162.00650959490923\n",
      "episode: 63 reward: -144.31433004527275\n",
      "episode: 64 reward: -158.39695985840814\n",
      "episode: 65 reward: -149.53553593059556\n",
      "episode: 66 reward: -138.61015359353695\n",
      "episode: 67 reward: -148.8204099096258\n",
      "episode: 68 reward: -151.26462113565205\n",
      "episode: 69 reward: -148.10503325322165\n",
      "episode: 70 reward: -140.7332007627955\n",
      "episode: 71 reward: -133.9259796824489\n",
      "episode: 72 reward: -126.7884253989375\n",
      "episode: 73 reward: -132.95628022418848\n",
      "episode: 74 reward: -141.18171023622105\n",
      "episode: 75 reward: -163.7404253824321\n",
      "episode: 76 reward: -138.52162802067673\n",
      "episode: 77 reward: -153.0564869129016\n",
      "episode: 78 reward: -140.4653132161662\n",
      "episode: 79 reward: -144.86479885724003\n",
      "episode: 80 reward: -142.8487733242128\n",
      "episode: 81 reward: -138.86293903909217\n",
      "episode: 82 reward: -147.20259223048225\n",
      "episode: 83 reward: -132.86494578492508\n",
      "episode: 84 reward: -131.97411818065225\n",
      "episode: 85 reward: -148.80566647054047\n",
      "episode: 86 reward: -146.05225861748812\n",
      "episode: 87 reward: -134.58453324704817\n",
      "episode: 88 reward: -145.70972029887253\n",
      "episode: 89 reward: -153.52206924166367\n",
      "episode: 90 reward: -157.43806431754388\n",
      "episode: 91 reward: -143.4346588886922\n",
      "episode: 92 reward: -142.8968937221655\n",
      "episode: 93 reward: -157.5427189385071\n",
      "episode: 94 reward: -153.67371645560894\n",
      "episode: 95 reward: -143.74904159751185\n",
      "episode: 96 reward: -159.71120297339104\n",
      "episode: 97 reward: -154.06114140657849\n",
      "episode: 98 reward: -122.87035190944187\n",
      "episode: 99 reward: -142.23275597188564\n",
      "episode: 100 reward: -144.24745387498407\n",
      "episode: 101 reward: -158.1145553347498\n",
      "episode: 102 reward: -141.2675766808581\n",
      "episode: 103 reward: -136.0276205516279\n",
      "episode: 104 reward: -141.7066332856712\n",
      "episode: 105 reward: -163.1398868007631\n",
      "episode: 106 reward: -124.98366945866528\n",
      "episode: 107 reward: -139.91945946435885\n",
      "episode: 108 reward: -143.8232003862374\n",
      "episode: 109 reward: -144.612551698111\n",
      "episode: 110 reward: -144.90867116911141\n",
      "episode: 111 reward: -138.24975799232678\n",
      "episode: 112 reward: -158.0040692363459\n",
      "episode: 113 reward: -144.89767258245513\n",
      "episode: 114 reward: -135.436598869799\n",
      "episode: 115 reward: -150.32456767519142\n",
      "episode: 116 reward: -126.56528771569924\n",
      "episode: 117 reward: -141.99621230556312\n",
      "episode: 118 reward: -158.52849273816915\n",
      "episode: 119 reward: -147.9070518910322\n",
      "episode: 120 reward: -161.5288341160527\n",
      "episode: 121 reward: -148.98042240387025\n",
      "episode: 122 reward: -177.95586700093853\n",
      "episode: 123 reward: -147.7801820163337\n",
      "episode: 124 reward: -144.4183815510239\n",
      "episode: 125 reward: -140.9447430201204\n",
      "episode: 126 reward: -143.11888579484233\n",
      "episode: 127 reward: -140.28179390133994\n",
      "episode: 128 reward: -145.25204365367722\n",
      "episode: 129 reward: -144.9405725548886\n",
      "episode: 130 reward: -156.13189392768118\n",
      "episode: 131 reward: -163.39011315892625\n",
      "episode: 132 reward: -152.54385875230676\n",
      "episode: 133 reward: -146.0705450720939\n",
      "episode: 134 reward: -152.56820233467073\n",
      "episode: 135 reward: -162.42846809489848\n",
      "episode: 136 reward: -139.46033732791548\n",
      "episode: 137 reward: -144.23838214639366\n",
      "episode: 138 reward: -132.52368434389845\n",
      "episode: 139 reward: -148.55260107138653\n",
      "episode: 140 reward: -149.08470638138527\n",
      "episode: 141 reward: -144.01767002032614\n",
      "episode: 142 reward: -133.76179863916522\n",
      "episode: 143 reward: -143.33112898118097\n",
      "episode: 144 reward: -164.74019678755508\n",
      "episode: 145 reward: -157.73182955040434\n",
      "episode: 146 reward: -158.38316082433764\n",
      "episode: 147 reward: -155.5217570506826\n",
      "episode: 148 reward: -127.15714400498358\n",
      "episode: 149 reward: -153.80424615065883\n",
      "episode: 150 reward: -154.28207849632574\n",
      "episode: 151 reward: -150.5298352393948\n",
      "episode: 152 reward: -134.62661929156496\n",
      "episode: 153 reward: -151.04328711388166\n",
      "episode: 154 reward: -145.77669460442812\n",
      "episode: 155 reward: -153.29733031051254\n",
      "episode: 156 reward: -155.26359333764518\n",
      "episode: 157 reward: -131.28975265483706\n",
      "episode: 158 reward: -148.46403570464352\n",
      "episode: 159 reward: -147.6745770158553\n",
      "episode: 160 reward: -150.99951696041626\n",
      "episode: 161 reward: -141.39337532819766\n",
      "episode: 162 reward: -163.84411780612064\n",
      "episode: 163 reward: -146.37636892161524\n",
      "episode: 164 reward: -142.9463885647546\n",
      "episode: 165 reward: -146.19303434569287\n",
      "episode: 166 reward: -167.97522754483003\n",
      "episode: 167 reward: -162.28378282210517\n",
      "episode: 168 reward: -135.71178275748082\n",
      "episode: 169 reward: -128.40300592287005\n",
      "episode: 170 reward: -157.56116774514393\n",
      "episode: 171 reward: -151.74676167085514\n",
      "episode: 172 reward: -148.4841355601124\n",
      "episode: 173 reward: -142.50790224620138\n",
      "episode: 174 reward: -155.12268394572018\n",
      "episode: 175 reward: -133.71876012770113\n",
      "episode: 176 reward: -140.79324209707372\n",
      "episode: 177 reward: -157.44594253063082\n",
      "episode: 178 reward: -149.50924726103767\n",
      "episode: 179 reward: -144.51374255400506\n",
      "episode: 180 reward: -151.68545483264\n",
      "episode: 181 reward: -143.46212504598773\n",
      "episode: 182 reward: -147.26565234699927\n",
      "episode: 183 reward: -148.14481124328745\n",
      "episode: 184 reward: -145.26354476795186\n",
      "episode: 185 reward: -143.13205009260997\n",
      "episode: 186 reward: -141.11651693183762\n",
      "episode: 187 reward: -148.32062110888612\n",
      "episode: 188 reward: -129.4674634324257\n",
      "episode: 189 reward: -145.87078896381553\n",
      "episode: 190 reward: -126.18221565485692\n",
      "episode: 191 reward: -135.35147959789805\n",
      "episode: 192 reward: -158.98215349323576\n",
      "episode: 193 reward: -155.87458135537668\n",
      "episode: 194 reward: -141.88689682964966\n",
      "episode: 195 reward: -143.58711193085148\n",
      "episode: 196 reward: -151.5240229153511\n",
      "episode: 197 reward: -130.1670701709796\n",
      "episode: 198 reward: -141.79034789694393\n",
      "episode: 199 reward: -165.0027333104241\n",
      "episode: 200 reward: -153.32572628012213\n",
      "episode: 201 reward: -149.1671976312265\n",
      "episode: 202 reward: -151.98634314963655\n",
      "episode: 203 reward: -152.18213786380187\n",
      "episode: 204 reward: -147.36009226994344\n",
      "episode: 205 reward: -146.88587187853338\n",
      "episode: 206 reward: -152.01943643486922\n",
      "episode: 207 reward: -159.3312421264955\n",
      "episode: 208 reward: -146.99839359754208\n",
      "episode: 209 reward: -148.2117518666895\n",
      "episode: 210 reward: -144.49924408193837\n",
      "episode: 211 reward: -163.1504127912687\n",
      "episode: 212 reward: -129.51673701505177\n",
      "episode: 213 reward: -153.67309550437673\n",
      "episode: 214 reward: -135.79897057313548\n",
      "episode: 215 reward: -147.2161140358745\n",
      "episode: 216 reward: -155.04887145181488\n",
      "episode: 217 reward: -147.6282250771791\n",
      "episode: 218 reward: -142.10476407300484\n",
      "episode: 219 reward: -148.83353259022851\n",
      "episode: 220 reward: -150.3059410775018\n",
      "episode: 221 reward: -143.23549971711765\n",
      "episode: 222 reward: -160.49289021417135\n",
      "episode: 223 reward: -141.47873099082952\n",
      "episode: 224 reward: -151.39233318279724\n",
      "episode: 225 reward: -151.63067003235366\n",
      "episode: 226 reward: -136.71865661435123\n",
      "episode: 227 reward: -148.57450397287133\n",
      "episode: 228 reward: -161.0572866945482\n",
      "episode: 229 reward: -148.3375293501847\n",
      "episode: 230 reward: -170.78549461504932\n",
      "episode: 231 reward: -146.59859366519754\n",
      "episode: 232 reward: -170.22221655399522\n",
      "episode: 233 reward: -154.36243581047702\n",
      "episode: 234 reward: -169.72456582676548\n",
      "episode: 235 reward: -145.97314512887633\n",
      "episode: 236 reward: -164.17844228408205\n",
      "episode: 237 reward: -150.0912412972444\n",
      "episode: 238 reward: -142.89935818253667\n",
      "episode: 239 reward: -157.5457238941065\n",
      "episode: 240 reward: -164.89311125339933\n",
      "episode: 241 reward: -162.00322475356677\n",
      "episode: 242 reward: -140.94804184532433\n",
      "episode: 243 reward: -161.6141384311267\n",
      "episode: 244 reward: -156.29946324661984\n",
      "episode: 245 reward: -153.5263844484704\n",
      "episode: 246 reward: -156.14517692580495\n",
      "episode: 247 reward: -169.6851130588021\n",
      "episode: 248 reward: -128.52879729956172\n",
      "episode: 249 reward: -153.59988456701387\n",
      "episode: 250 reward: -143.51720302649235\n",
      "episode: 251 reward: -158.68475621938046\n",
      "episode: 252 reward: -151.89983412736535\n",
      "episode: 253 reward: -149.45916781864682\n",
      "episode: 254 reward: -171.3692889590322\n",
      "episode: 255 reward: -153.80769368379447\n",
      "episode: 256 reward: -135.75418285453108\n",
      "episode: 257 reward: -149.14581978101066\n",
      "episode: 258 reward: -157.3753308432987\n",
      "episode: 259 reward: -148.61043727547985\n",
      "episode: 260 reward: -136.92633276993266\n",
      "episode: 261 reward: -137.44343021581446\n",
      "episode: 262 reward: -156.1687934795513\n",
      "episode: 263 reward: -128.76624367150993\n",
      "episode: 264 reward: -148.64679033319484\n",
      "episode: 265 reward: -157.65623602901292\n",
      "episode: 266 reward: -129.15690805907442\n",
      "episode: 267 reward: -143.2095668651381\n",
      "episode: 268 reward: -159.15506182079437\n",
      "episode: 269 reward: -155.09925526829\n",
      "episode: 270 reward: -150.74911359505825\n",
      "episode: 271 reward: -126.1541257088143\n",
      "episode: 272 reward: -138.38733140296026\n",
      "episode: 273 reward: -150.70399226695653\n",
      "episode: 274 reward: -153.9146853879373\n",
      "episode: 275 reward: -142.48447554508266\n",
      "episode: 276 reward: -156.90953330788764\n",
      "episode: 277 reward: -166.1422976527644\n",
      "episode: 278 reward: -138.60971701570134\n",
      "episode: 279 reward: -133.7247245845719\n",
      "episode: 280 reward: -151.14816888597892\n",
      "episode: 281 reward: -165.09714151244305\n",
      "episode: 282 reward: -143.04426502626498\n",
      "episode: 283 reward: -172.89727365125668\n",
      "episode: 284 reward: -150.07885792305646\n",
      "episode: 285 reward: -144.61985303393462\n",
      "episode: 286 reward: -148.62904614566725\n",
      "episode: 287 reward: -146.4451973367081\n",
      "episode: 288 reward: -157.5228786527639\n",
      "episode: 289 reward: -149.04416687519708\n",
      "episode: 290 reward: -131.01911981177673\n",
      "episode: 291 reward: -154.8987347886869\n",
      "episode: 292 reward: -142.45292199880683\n",
      "episode: 293 reward: -149.38328957707716\n",
      "episode: 294 reward: -156.92892120667122\n",
      "episode: 295 reward: -148.28970891544756\n",
      "episode: 296 reward: -173.0325201306069\n",
      "episode: 297 reward: -148.3427460301339\n",
      "episode: 298 reward: -129.3867709547314\n",
      "episode: 299 reward: -139.8187663028191\n",
      "episode: 300 reward: -143.94013622137976\n",
      "episode: 301 reward: -133.56575048826696\n",
      "episode: 302 reward: -144.0499665949179\n",
      "episode: 303 reward: -147.80470428272812\n",
      "episode: 304 reward: -140.81589314061074\n",
      "episode: 305 reward: -132.6077720721687\n",
      "episode: 306 reward: -141.4697192442678\n",
      "episode: 307 reward: -157.46954867358912\n",
      "episode: 308 reward: -146.32005535462784\n",
      "episode: 309 reward: -138.8328704006331\n",
      "episode: 310 reward: -139.3975512125632\n",
      "episode: 311 reward: -148.7019201818536\n",
      "episode: 312 reward: -157.66753057482867\n",
      "episode: 313 reward: -144.56176098144405\n",
      "episode: 314 reward: -152.2177157899031\n",
      "episode: 315 reward: -140.53099433089096\n",
      "episode: 316 reward: -130.6079439019419\n",
      "episode: 317 reward: -156.23083033553738\n",
      "episode: 318 reward: -148.67309294267926\n",
      "episode: 319 reward: -155.76229029540903\n",
      "episode: 320 reward: -149.5719181171535\n",
      "episode: 321 reward: -157.27972757353874\n",
      "episode: 322 reward: -140.60238812625062\n",
      "episode: 323 reward: -155.91788496509085\n",
      "episode: 324 reward: -150.2525239587053\n",
      "episode: 325 reward: -152.6094393458615\n",
      "episode: 326 reward: -157.78883275385408\n",
      "episode: 327 reward: -140.92897425568734\n",
      "episode: 328 reward: -153.5154878636915\n",
      "episode: 329 reward: -151.59787940179143\n",
      "episode: 330 reward: -131.5391419640712\n",
      "episode: 331 reward: -147.958164169481\n",
      "episode: 332 reward: -140.07567248837472\n",
      "episode: 333 reward: -145.5935088944366\n",
      "episode: 334 reward: -151.39716985789548\n",
      "episode: 335 reward: -148.29587385403664\n",
      "episode: 336 reward: -153.45111323013833\n",
      "episode: 337 reward: -138.5570146731563\n",
      "episode: 338 reward: -148.82266795082222\n",
      "episode: 339 reward: -143.82212284052966\n",
      "episode: 340 reward: -132.59838092809065\n",
      "episode: 341 reward: -138.51117541043988\n",
      "episode: 342 reward: -132.78649458462377\n",
      "episode: 343 reward: -137.25939117471182\n",
      "episode: 344 reward: -144.3643457323114\n",
      "episode: 345 reward: -140.26027413504812\n",
      "episode: 346 reward: -154.17987545613227\n",
      "episode: 347 reward: -135.58840030431156\n",
      "episode: 348 reward: -153.7146955782923\n",
      "episode: 349 reward: -162.32889491176815\n",
      "episode: 350 reward: -140.96109376800638\n",
      "episode: 351 reward: -162.53302499836306\n",
      "episode: 352 reward: -157.93985052226373\n",
      "episode: 353 reward: -172.88892459828398\n",
      "episode: 354 reward: -159.5063955111892\n",
      "episode: 355 reward: -132.95914835823322\n",
      "episode: 356 reward: -165.9466175517027\n",
      "episode: 357 reward: -145.91800046679134\n",
      "episode: 358 reward: -142.29546140946948\n",
      "episode: 359 reward: -152.86597065888958\n",
      "episode: 360 reward: -144.7566568919364\n",
      "episode: 361 reward: -150.76834589425602\n",
      "episode: 362 reward: -133.8612296554925\n",
      "episode: 363 reward: -146.03950357489208\n",
      "episode: 364 reward: -128.09569357137858\n",
      "episode: 365 reward: -149.27729179293985\n",
      "episode: 366 reward: -159.8306099763212\n",
      "episode: 367 reward: -144.9056177012162\n",
      "episode: 368 reward: -169.21216669864424\n",
      "episode: 369 reward: -151.80166142931674\n",
      "episode: 370 reward: -142.81795010842393\n",
      "episode: 371 reward: -147.0314964295872\n",
      "episode: 372 reward: -153.13691668443926\n",
      "episode: 373 reward: -139.7995742498729\n",
      "episode: 374 reward: -158.56627841292567\n",
      "episode: 375 reward: -145.33275972993863\n",
      "episode: 376 reward: -137.94904068852375\n",
      "episode: 377 reward: -144.3864294492891\n",
      "episode: 378 reward: -141.5784212576756\n",
      "episode: 379 reward: -148.70454221076082\n",
      "episode: 380 reward: -157.5297625096093\n",
      "episode: 381 reward: -144.5105352292126\n",
      "episode: 382 reward: -143.99634964945253\n",
      "episode: 383 reward: -164.99353839768725\n",
      "episode: 384 reward: -159.77098997703294\n",
      "episode: 385 reward: -147.45769772034757\n",
      "episode: 386 reward: -161.1441139777935\n",
      "episode: 387 reward: -142.079509357691\n",
      "episode: 388 reward: -146.33211607825413\n",
      "episode: 389 reward: -158.3084062746376\n",
      "episode: 390 reward: -161.28593317254885\n",
      "episode: 391 reward: -159.734256419136\n",
      "episode: 392 reward: -152.3878147932287\n",
      "episode: 393 reward: -144.048194797355\n",
      "episode: 394 reward: -148.6599533362919\n",
      "episode: 395 reward: -147.3147248514962\n",
      "episode: 396 reward: -145.31069892061674\n",
      "episode: 397 reward: -159.75568147936693\n",
      "episode: 398 reward: -145.58459936756154\n",
      "episode: 399 reward: -144.75217057455188\n",
      "episode: 400 reward: -143.99811962625793\n",
      "episode: 401 reward: -149.0114669874994\n",
      "episode: 402 reward: -142.68407642572166\n",
      "episode: 403 reward: -158.50553226416568\n",
      "episode: 404 reward: -144.73377719803392\n",
      "episode: 405 reward: -173.03153935926971\n",
      "episode: 406 reward: -137.11724148238193\n",
      "episode: 407 reward: -160.8533164123434\n",
      "episode: 408 reward: -145.05612194158238\n",
      "episode: 409 reward: -161.50766893367546\n",
      "episode: 410 reward: -147.11332134404603\n",
      "episode: 411 reward: -134.85296488577853\n",
      "episode: 412 reward: -162.68164473503137\n",
      "episode: 413 reward: -139.66564813835248\n",
      "episode: 414 reward: -139.55861208316702\n",
      "episode: 415 reward: -157.26421892908724\n",
      "episode: 416 reward: -145.85202948303407\n",
      "episode: 417 reward: -155.55748268186744\n",
      "episode: 418 reward: -152.14869055831062\n",
      "episode: 419 reward: -148.50483407590167\n",
      "episode: 420 reward: -148.57456689730205\n",
      "episode: 421 reward: -156.48069407103083\n",
      "episode: 422 reward: -138.4768811169507\n",
      "episode: 423 reward: -140.1224581347045\n",
      "episode: 424 reward: -152.96961399995106\n",
      "episode: 425 reward: -152.58125498725593\n",
      "episode: 426 reward: -139.5240931800307\n",
      "episode: 427 reward: -150.22273683824218\n",
      "episode: 428 reward: -130.23849530151773\n",
      "episode: 429 reward: -156.52925156989573\n",
      "episode: 430 reward: -155.19694707316108\n",
      "episode: 431 reward: -134.25566326941478\n",
      "episode: 432 reward: -144.22444459288923\n",
      "episode: 433 reward: -134.95535105945376\n",
      "episode: 434 reward: -163.1121187497364\n",
      "episode: 435 reward: -149.201546758616\n",
      "episode: 436 reward: -133.21797416292105\n",
      "episode: 437 reward: -156.1574143056578\n",
      "episode: 438 reward: -152.4202360212101\n",
      "episode: 439 reward: -142.17800797456394\n",
      "episode: 440 reward: -129.90697076774345\n",
      "episode: 441 reward: -146.36457666484696\n",
      "episode: 442 reward: -152.57626900251773\n",
      "episode: 443 reward: -147.93204846376264\n",
      "episode: 444 reward: -152.50947379453473\n",
      "episode: 445 reward: -146.8940636513319\n",
      "episode: 446 reward: -134.45237042492633\n",
      "episode: 447 reward: -135.49254747437755\n",
      "episode: 448 reward: -139.23762593129905\n",
      "episode: 449 reward: -140.72024405228362\n",
      "episode: 450 reward: -136.19081535654925\n",
      "episode: 451 reward: -137.05823910225325\n",
      "episode: 452 reward: -164.13416540672029\n",
      "episode: 453 reward: -140.51316505399677\n",
      "episode: 454 reward: -132.73509385404768\n",
      "episode: 455 reward: -143.5043859359353\n",
      "episode: 456 reward: -156.54346651416483\n",
      "episode: 457 reward: -159.1128949785996\n",
      "episode: 458 reward: -155.13615882363715\n",
      "episode: 459 reward: -151.71826514793594\n",
      "episode: 460 reward: -142.76885980419445\n",
      "episode: 461 reward: -146.74973841627656\n",
      "episode: 462 reward: -152.54217224615897\n",
      "episode: 463 reward: -122.62371637711587\n",
      "episode: 464 reward: -163.4734448840804\n",
      "episode: 465 reward: -134.81966066154328\n",
      "episode: 466 reward: -159.16391267270347\n",
      "episode: 467 reward: -150.99755691229421\n",
      "episode: 468 reward: -149.34974007531474\n",
      "episode: 469 reward: -145.52185188518533\n",
      "episode: 470 reward: -155.98144921103219\n",
      "episode: 471 reward: -156.3216710143017\n",
      "episode: 472 reward: -127.49592908962296\n",
      "episode: 473 reward: -143.34569918100522\n",
      "episode: 474 reward: -157.2265698591479\n",
      "episode: 475 reward: -144.6243808371672\n",
      "episode: 476 reward: -137.57544013802027\n",
      "episode: 477 reward: -147.6795815242955\n",
      "episode: 478 reward: -151.7898657509933\n",
      "episode: 479 reward: -139.78738013806722\n",
      "episode: 480 reward: -155.28326119093668\n",
      "episode: 481 reward: -142.00331955397002\n",
      "episode: 482 reward: -151.3815436587885\n",
      "episode: 483 reward: -146.26932103715177\n",
      "episode: 484 reward: -140.1324683013999\n",
      "episode: 485 reward: -141.3241556236583\n",
      "episode: 486 reward: -131.67637017714486\n",
      "episode: 487 reward: -151.11173974392833\n",
      "episode: 488 reward: -162.19651322767385\n",
      "episode: 489 reward: -160.97187288931195\n",
      "episode: 490 reward: -139.52437227497825\n",
      "episode: 491 reward: -159.13252723864838\n",
      "episode: 492 reward: -154.21015687833147\n",
      "episode: 493 reward: -143.77425362526708\n",
      "episode: 494 reward: -148.5802495883471\n",
      "episode: 495 reward: -145.9906178185662\n",
      "episode: 496 reward: -173.1927362215954\n",
      "episode: 497 reward: -139.51108113445162\n",
      "episode: 498 reward: -144.88325382861476\n",
      "episode: 499 reward: -151.7169342253298\n",
      "\n",
      "(50000, 30)\n",
      "sampled: 500 mean_reward: -147.82673050063494 success_rate: 0.01\n"
     ]
    }
   ],
   "source": [
    "from itertools import count\n",
    "\n",
    "max_expert_num = 50000\n",
    "num_steps = 0\n",
    "expert_traj = []\n",
    "sum_reward = 0\n",
    "success_num = 0\n",
    "for i_episode in count():\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    \n",
    "    while not done:\n",
    "        state = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "        dist, _ = model(state)\n",
    "        action = dist.sample().cpu().numpy()[0]\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "        expert_traj.append(np.hstack([state, action]))\n",
    "        num_steps += 1\n",
    "    sum_reward += total_reward\n",
    "    success_num += info[\"achieve\"]\n",
    "    print(\"episode:\", i_episode, \"reward:\", total_reward)\n",
    "    \n",
    "    if num_steps >= max_expert_num:\n",
    "        break\n",
    "        \n",
    "expert_traj = np.stack(expert_traj)\n",
    "print()\n",
    "print(expert_traj.shape)\n",
    "print(\"sampled:\",i_episode+1,\"mean_reward:\",sum_reward/(i_episode+1),\"success_rate:\",success_num/(i_episode+1))\n",
    "np.save(\"expert_traj.npy\", expert_traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            from IPython.core.debugger import Pdb; Pdb().set_trace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ex_traj_Pusher_PPO_TorchGAIL_500\n",
    "sampled: 500 mean_reward: -26.717197505464732 success_rate: 0.848"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL-a",
   "language": "python",
   "name": "rl-a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
